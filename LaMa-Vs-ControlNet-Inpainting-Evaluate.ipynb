{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3bba339-f63e-4eb2-bae9-df3396cd0097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: C:\\Users\\ng_mi\\AppData\\Roaming\\Python\\Python312\\site-packages\\lpips\\weights\\v0.1\\alex.pth\n",
      "Loaded LPIPS model from models/lpips\\lpips_alex.pth\n",
      "stabilityai/stable-diffusion-2-inpainting already exists. Skipping download.\n",
      "lllyasviel/control_v11p_sd15_inpaint already exists. Skipping download.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0b4f647c274478986b134c880f2feda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleLama inpaint saved: results\\lama\\im005.jpg\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb90ae2c64bf4addb0bd301defb51a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ControlNet inpaint saved: results\\controlnet\\im005.jpg\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 264\u001b[0m\n\u001b[0;32m    261\u001b[0m controlnet_result \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(out_controlnet)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# Evaluate metrics against the ground truth\u001b[39;00m\n\u001b[1;32m--> 264\u001b[0m lama_psnr, lama_ssim, lama_lpips \u001b[38;5;241m=\u001b[39m evaluate_metrics(gt_image, lama_result)\n\u001b[0;32m    265\u001b[0m controlnet_psnr, controlnet_ssim, controlnet_lpips \u001b[38;5;241m=\u001b[39m evaluate_metrics(gt_image, controlnet_result)\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluated \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 186\u001b[0m, in \u001b[0;36mevaluate_metrics\u001b[1;34m(gt_img, inpaint_img)\u001b[0m\n\u001b[0;32m    183\u001b[0m     inpaint_np \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(inpaint_img)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n\u001b[0;32m    185\u001b[0m psnr \u001b[38;5;241m=\u001b[39m compute_psnr(gt_np, inpaint_np, data_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m--> 186\u001b[0m ssim \u001b[38;5;241m=\u001b[39m compute_ssim(gt_np, inpaint_np, multichannel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m    188\u001b[0m gt_tensor \u001b[38;5;241m=\u001b[39m prepare_for_lpips(gt_img)\n\u001b[0;32m    189\u001b[0m inpaint_tensor \u001b[38;5;241m=\u001b[39m prepare_for_lpips(inpaint_img)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\skimage\\metrics\\_structural_similarity.py:186\u001b[0m, in \u001b[0;36mstructural_similarity\u001b[1;34m(im1, im2, win_size, gradient, data_range, channel_axis, gaussian_weights, full, **kwargs)\u001b[0m\n\u001b[0;32m    183\u001b[0m         win_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m7\u001b[39m  \u001b[38;5;66;03m# backwards compatibility\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many((np\u001b[38;5;241m.\u001b[39masarray(im1\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m-\u001b[39m win_size) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwin_size exceeds image extent. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEither ensure that your images are \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    189\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mat least 7x7; or pass win_size explicitly \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    190\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min the function call, with an odd value \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mless than or equal to the smaller side of your \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages. If your images are multichannel \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    193\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(with color channels), set channel_axis to \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe axis number corresponding to the channels.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    195\u001b[0m     )\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (win_size \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWindow size must be odd.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import csv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from diffusers import ControlNetModel, StableDiffusionInpaintPipeline\n",
    "from skimage.metrics import peak_signal_noise_ratio as compute_psnr\n",
    "from skimage.metrics import structural_similarity as compute_ssim\n",
    "import lpips  # pip install lpips\n",
    "\n",
    "# ---------------------------\n",
    "# Inpainting functions\n",
    "# ---------------------------\n",
    "def run_lama_inpaint(image_path, mask_path, output_path):\n",
    "    from simple_lama_inpainting import SimpleLama  # import here in case it's not global\n",
    "    simple_lama = SimpleLama()\n",
    "    image = Image.open(image_path)\n",
    "    mask = Image.open(mask_path).convert('L')\n",
    "    result = simple_lama(image, mask)\n",
    "    result.save(output_path)\n",
    "    print(f\"SimpleLama inpaint saved: {output_path}\")\n",
    "\n",
    "# ---------------------------\n",
    "# ControlNet helper functions\n",
    "# ---------------------------\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "def clean_huggingface_cache(model_path):\n",
    "    \"\"\"Remove unnecessary Hugging Face cache directories and .lock files.\"\"\"\n",
    "    for root, dirs, files in os.walk(model_path, topdown=False):\n",
    "        for name in files:\n",
    "            if name.endswith(\".lock\"):\n",
    "                os.remove(os.path.join(root, name))\n",
    "        for name in dirs:\n",
    "            if name.startswith(\"models--\") or name == \"temp\":\n",
    "                shutil.rmtree(os.path.join(root, name), ignore_errors=True)\n",
    "\n",
    "def get_latest_snapshot(model_path):\n",
    "    \"\"\"Find and move the correct snapshot folder for a downloaded model.\"\"\"\n",
    "    if os.path.exists(model_path):\n",
    "        for subdir in os.listdir(model_path):\n",
    "            snapshot_path = os.path.join(model_path, subdir, \"snapshots\")\n",
    "            if os.path.exists(snapshot_path):\n",
    "                snapshots = sorted(os.listdir(snapshot_path), reverse=True)\n",
    "                if snapshots:\n",
    "                    latest_snapshot = os.path.join(snapshot_path, snapshots[0])\n",
    "                    for file_name in os.listdir(latest_snapshot):\n",
    "                        src = os.path.join(latest_snapshot, file_name)\n",
    "                        dest = os.path.join(model_path, file_name)\n",
    "                        if not os.path.exists(dest):\n",
    "                            shutil.move(src, dest)\n",
    "                    shutil.rmtree(os.path.dirname(latest_snapshot), ignore_errors=True)\n",
    "                    return model_path\n",
    "    return model_path\n",
    "\n",
    "def check_and_download_model(model_name, model_path, is_controlnet=False):\n",
    "    \"\"\"Check if the model exists; if not, download and move it to the correct directory.\"\"\"\n",
    "    if is_controlnet:\n",
    "        model_path = os.path.join(model_path, \"controlnet\")\n",
    "    else:\n",
    "        model_path = os.path.join(model_path, \"stable-diffusion\")\n",
    "\n",
    "    if os.path.exists(model_path) and os.listdir(model_path):\n",
    "        print(f\"{model_name} already exists. Skipping download.\")\n",
    "        return\n",
    "\n",
    "    print(f\"{model_name} not found. Downloading...\")\n",
    "    temp_dir = os.path.join(\"models\", \"temp\")\n",
    "\n",
    "    if is_controlnet:\n",
    "        ControlNetModel.from_pretrained(model_name, cache_dir=temp_dir)\n",
    "    else:\n",
    "        StableDiffusionInpaintPipeline.from_pretrained(model_name, cache_dir=temp_dir)\n",
    "\n",
    "    correct_model_path = get_latest_snapshot(temp_dir)\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    for file_name in os.listdir(correct_model_path):\n",
    "        src = os.path.join(correct_model_path, file_name)\n",
    "        dest = os.path.join(model_path, file_name)\n",
    "        if not os.path.exists(dest):\n",
    "            shutil.move(src, dest)\n",
    "    shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "    print(f\"{model_name} downloaded and saved in {model_path}\")\n",
    "\n",
    "def load_controlnet():\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    models_dir = \"models\"\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    controlnet_dir = os.path.join(models_dir, \"controlnet\")\n",
    "    stable_diffusion_dir = os.path.join(models_dir, \"stable-diffusion\")\n",
    "    os.makedirs(controlnet_dir, exist_ok=True)\n",
    "    os.makedirs(stable_diffusion_dir, exist_ok=True)\n",
    "\n",
    "    check_and_download_model(\"stabilityai/stable-diffusion-2-inpainting\", models_dir, is_controlnet=False)\n",
    "    check_and_download_model(\"lllyasviel/control_v11p_sd15_inpaint\", models_dir, is_controlnet=True)\n",
    "\n",
    "    clean_huggingface_cache(models_dir)\n",
    "\n",
    "    pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
    "        stable_diffusion_dir, torch_dtype=torch_dtype, local_files_only=True\n",
    "    ).to(device, dtype=torch_dtype)\n",
    "    # If needed, integrate the controlnet model into the pipeline.\n",
    "    return pipe\n",
    "\n",
    "def make_divisible_by_8(size):\n",
    "    \"\"\"Ensure both width and height are divisible by 8.\"\"\"\n",
    "    width, height = size\n",
    "    width = (width // 8) * 8\n",
    "    height = (height // 8) * 8\n",
    "    return width, height\n",
    "\n",
    "def run_controlnet_inpaint(image_path, mask_path, pipe, reference_images, prompt, output_path):\n",
    "    # Open image and mask\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    mask = Image.open(mask_path).convert(\"L\")\n",
    "    original_size = image.size\n",
    "    adjusted_size = make_divisible_by_8(original_size)\n",
    "\n",
    "    conditioning = None\n",
    "    if reference_images:\n",
    "        conditioning = [\n",
    "            img.resize(adjusted_size, Image.Resampling.LANCZOS)\n",
    "            for img in reference_images\n",
    "        ]\n",
    "\n",
    "    result = pipe(\n",
    "        prompt=prompt,\n",
    "        image=image.resize(adjusted_size, Image.Resampling.LANCZOS),\n",
    "        mask_image=mask.resize(adjusted_size, Image.Resampling.LANCZOS),\n",
    "        conditioning_image=conditioning,\n",
    "        height=adjusted_size[1],\n",
    "        width=adjusted_size[0]\n",
    "    ).images[0]\n",
    "    result = result.resize(original_size, Image.Resampling.LANCZOS)\n",
    "    result.save(output_path)\n",
    "    print(f\"ControlNet inpaint saved: {output_path}\")\n",
    "\n",
    "# ---------------------------\n",
    "# LPIPS model loading\n",
    "# ---------------------------\n",
    "def load_lpips_model(model_dir=\"models/lpips\"):\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    model_path = os.path.join(model_dir, \"lpips_alex.pth\")\n",
    "    model = lpips.LPIPS(net='alex')\n",
    "    if os.path.exists(model_path):\n",
    "        # Load the saved state dictionary\n",
    "        model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "        print(f\"Loaded LPIPS model from {model_path}\")\n",
    "    else:\n",
    "        # Save the model state dictionary to the file for future use\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(f\"Saved LPIPS model to {model_path}\")\n",
    "    model.eval()\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "    return model\n",
    "\n",
    "# Load LPIPS model (cached in models folder)\n",
    "lpips_model = load_lpips_model()\n",
    "\n",
    "# ---------------------------\n",
    "# Evaluation functions\n",
    "# ---------------------------\n",
    "def prepare_for_lpips(pil_image):\n",
    "    # Convert image to tensor in range [0,1] then normalize to [-1,1]\n",
    "    tensor = transforms.ToTensor()(pil_image).unsqueeze(0)\n",
    "    tensor = tensor * 2 - 1\n",
    "    if torch.cuda.is_available():\n",
    "        tensor = tensor.cuda()\n",
    "    return tensor\n",
    "\n",
    "def evaluate_metrics(gt_img, inpaint_img):\n",
    "    # Convert images to numpy arrays (normalized to [0,1])\n",
    "    gt_np = np.array(gt_img).astype(np.float32) / 255.0\n",
    "    inpaint_np = np.array(inpaint_img).astype(np.float32) / 255.0\n",
    "\n",
    "    # Resize if needed\n",
    "    if gt_np.shape != inpaint_np.shape:\n",
    "        inpaint_img = inpaint_img.resize(gt_img.size, Image.Resampling.LANCZOS)\n",
    "        inpaint_np = np.array(inpaint_img).astype(np.float32) / 255.0\n",
    "\n",
    "    psnr = compute_psnr(gt_np, inpaint_np, data_range=1.0)\n",
    "    ssim = compute_ssim(gt_np, inpaint_np, multichannel=True, data_range=1.0)\n",
    "\n",
    "    gt_tensor = prepare_for_lpips(gt_img)\n",
    "    inpaint_tensor = prepare_for_lpips(inpaint_img)\n",
    "    with torch.no_grad():\n",
    "        lpips_distance = lpips_model(gt_tensor, inpaint_tensor).item()\n",
    "\n",
    "    return psnr, ssim, lpips_distance\n",
    "\n",
    "# ---------------------------\n",
    "# Main combined evaluation\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Directories for input and output\n",
    "    image_dir = \"DUT-OMRON-image\"   # Ground truth images (JPEG)\n",
    "    mask_dir = \"DUT-OMRON-mask\"     # Masks (PNG)\n",
    "    results_dir = \"results\"\n",
    "    lama_dir = os.path.join(results_dir, \"lama\")\n",
    "    controlnet_dir = os.path.join(results_dir, \"controlnet\")\n",
    "    os.makedirs(lama_dir, exist_ok=True)\n",
    "    os.makedirs(controlnet_dir, exist_ok=True)\n",
    "\n",
    "    # Load ControlNet pipeline (and optionally reference images)\n",
    "    pipe = load_controlnet()\n",
    "    reference_images_dir = \"images/reference_images\"\n",
    "    reference_images = []\n",
    "    if os.path.exists(reference_images_dir):\n",
    "        reference_images = [\n",
    "            Image.open(img).convert(\"RGB\")\n",
    "            for img in glob.glob(os.path.join(reference_images_dir, \"*.*\"))\n",
    "        ]\n",
    "\n",
    "    # Define a prompt for ControlNet\n",
    "    prompt = (\n",
    "        \"Restore missing areas by seamlessly extending the surroundings. \"\n",
    "        \"Maintain consistency in color, texture, landmarks, and lighting.\"\n",
    "    )\n",
    "\n",
    "    # List to store evaluation results\n",
    "    evaluation_results = []\n",
    "    \n",
    "    # Process each ground truth image (JPEG) in DUT-OMRON-image\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.lower().endswith((\".jpg\", \".jpeg\")):\n",
    "            gt_path = os.path.join(image_dir, filename)\n",
    "            gt_image = Image.open(gt_path).convert(\"RGB\")\n",
    "            \n",
    "            # Get corresponding mask using the same base name with .png extension\n",
    "            base_name = os.path.splitext(filename)[0]\n",
    "            mask_filename = base_name + \".png\"\n",
    "            mask_path = os.path.join(mask_dir, mask_filename)\n",
    "            if not os.path.exists(mask_path):\n",
    "                print(f\"Mask for {filename} not found as {mask_filename}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Define output paths for both inpainting methods\n",
    "            out_lama = os.path.join(lama_dir, filename)\n",
    "            out_controlnet = os.path.join(controlnet_dir, filename)\n",
    "\n",
    "            # Run SimpleLama inpainting\n",
    "            try:\n",
    "                run_lama_inpaint(gt_path, mask_path, out_lama)\n",
    "            except Exception as e:\n",
    "                print(f\"Error in SimpleLama for {filename}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Run ControlNet inpainting\n",
    "            try:\n",
    "                run_controlnet_inpaint(gt_path, mask_path, pipe, reference_images, prompt, out_controlnet)\n",
    "            except Exception as e:\n",
    "                print(f\"Error in ControlNet for {filename}: {e}\")\n",
    "                continue\n",
    "\n",
    "            # Load the inpainted results for evaluation\n",
    "            lama_result = Image.open(out_lama).convert(\"RGB\")\n",
    "            controlnet_result = Image.open(out_controlnet).convert(\"RGB\")\n",
    "            \n",
    "            # Evaluate metrics against the ground truth\n",
    "            lama_psnr, lama_ssim, lama_lpips = evaluate_metrics(gt_image, lama_result)\n",
    "            controlnet_psnr, controlnet_ssim, controlnet_lpips = evaluate_metrics(gt_image, controlnet_result)\n",
    "            \n",
    "            print(f\"Evaluated {filename}:\")\n",
    "            print(f\"  SimpleLama -> PSNR: {lama_psnr:.2f}, SSIM: {lama_ssim:.4f}, LPIPS: {lama_lpips:.4f}\")\n",
    "            print(f\"  ControlNet -> PSNR: {controlnet_psnr:.2f}, SSIM: {controlnet_ssim:.4f}, LPIPS: {controlnet_lpips:.4f}\")\n",
    "            \n",
    "            # Store results for CSV\n",
    "            evaluation_results.append({\n",
    "                'filename': filename,\n",
    "                'lama_PSNR': lama_psnr,\n",
    "                'lama_SSIM': lama_ssim,\n",
    "                'lama_LPIPS': lama_lpips,\n",
    "                'controlnet_PSNR': controlnet_psnr,\n",
    "                'controlnet_SSIM': controlnet_ssim,\n",
    "                'controlnet_LPIPS': controlnet_lpips\n",
    "            })\n",
    "\n",
    "    # Write the evaluation metrics to a CSV file\n",
    "    csv_file_path = \"evaluation_results.csv\"\n",
    "    csv_fields = ['filename', \n",
    "                  'lama_PSNR', 'lama_SSIM', 'lama_LPIPS', \n",
    "                  'controlnet_PSNR', 'controlnet_SSIM', 'controlnet_LPIPS']\n",
    "    with open(csv_file_path, mode='w', newline='') as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=csv_fields)\n",
    "        writer.writeheader()\n",
    "        for row in evaluation_results:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    print(f\"\\nEvaluation complete. Results saved to {csv_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a76827-2ef3-46a0-bd8a-24546147df11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
